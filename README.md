# AWS
There are many other tutorials; 
I just seem to/or have worked well for me. I have numbered them in order of increased difficulty in getting started (not necessary 
difficult of work, good tutorials manage this within the tutorial):

1.	Cloud Academy search for (AWS, or Machine Learning in the cloud)
2.	https://aws.amazon.com/training/self-paced-labs/
3.	Qwiklabs
a.	https://amazon.qwiklabs.com/catalog?locale=en
b.	https://amazon.qwiklabs.com/quests/20?locale=en
4.	Code from Hans-on Labs (https://aws.amazon.com/serverless-workshops/)
a.	https://github.com/aws-samples/aws-serverless-workshops/tree/master/WebApplication
b.	https://github.com/aws-samples/aws-lambda-zombie-workshop


# Autoencoder:

https://blog.csdn.net/changyuanchn/article/details/15681853

https://github.com/snatch59/keras-autoencoders

https://blog.keras.io/building-autoencoders-in-keras.html

https://github.com/keras-team/keras/tree/master/examples

https://www.kaggle.com/apapiu/manifold-learning-and-autoencoders

https://www.kaggle.com/rvislaywade/visualizing-mnist-using-a-variational-autoencoder

https://medium.com/@curiousily/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hackers-part-vii-20e0c85301bd

# KS test
https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test


# Optimization Methods
•	https://towardsdatascience.com/neural-network-optimization-algorithms-1a44c282f61d

•	https://arxiv.org/abs/1609.04747

•	http://cs231n.github.io/neural-networks-3/

•	https://theberkeleyview.wordpress.com/2015/11/19/berkeleyview-for-adam-a-method-for-stochastic-optimization/

•	https://www.coursera.org/lecture/deep-neural-network/adam-optimization-algorithm-w9VCZ

•	http://ruder.io/optimizing-gradient-descent/
